% !TEX root = hazelnut-dynamics.tex
\newcommand{\calculusSec}{Hazelnut Live}
\section{\calculusSec}
\label{sec:calculus}
% \def \TirNameStyle \Vtexttt{#1}{{#1}}



\input{fig-syntax}

We will now make the intuitions developed in the previous section formally
precise by specifying a core calculus, which we call \HazelnutLive, and
characterizing its metatheory.

\noindent
\parahead{Overview} The syntax of the core calculus given in
Fig.~\ref{fig:hazelnut-live-syntax} consists of types and expressions with
holes.  We distinguish between {external} expressions, $e$, and {internal}
expressions, $d$.  External expressions correspond to programs as entered
by the programmer (see Sec.~\ref{sec:intro} for discussion of implicit,
manual, semi-automated and fully automated hole entry methods).  Each
well-typed external expression (see Sec.~\ref{sec:external-statics} below)
elaborates to a well-typed internal expression (see
Sec.~\ref{sec:elaboration}) before it is evaluated (see
Sec.~\ref{sec:evaluation}).  We take this approach, notably also taken in
the ``redefinition'' of Standard ML by \citet{Harper00atype-theoretic},
because (1) the external language supports type inference and explicit type
ascriptions, $\hexp : \htau$, but it is formally simpler to eliminate
ascriptions and specify a type assignment system when defining the dynamic
semantics; and (2) we need additional syntactic machinery during evaluation
for tracking hole closures and dynamic type casts.  This machinery is
inserted by elaboration, rather than entered explicitly by the programmer.
In this regard, the internal language is analogous to the cast calculus in
the gradually typed lambda calculus
\cite{DBLP:conf/snapl/SiekVCB15,Siek06a}, though as we will see the
\HazelnutLive internal language goes beyond the cast calculus in several
respects. We have mechanized these formal developments using the Agda proof
assistant \cite{norell:thesis,norell2009dependently} (see
Sec.~\ref{sec:agda-mechanization}). Rule names in this section,
e.g. \rulename{SVar}, correspond to variables from the
mechanization. The \Hazel implementation substantially follows the formal
specification of \Hazelnut (for the editor) and \HazelnutLive
(for the evaluator). We can formally state a continuity invariant for a
putative combined calculus (see Sec.~\ref{sec:implementation}).

% \rkc{this syntactic sugar is used in four places: ITCastSucceed, ITCastFail,
% ITGround, and ITExpand. that's not many, and those rules don't look much more
% cluttered without the sugar, so consider eliminating it. if so, just toggle the
% definition of the dcastthree macro to the unsugared option.}

\subsection{Static Semantics of the External Language}
\label{sec:external-statics}

\input{fig-bidirectional-typing}

We start with the type system of the \HazelnutLive external language,
which closely follows the \Hazelnut type system \cite{popl-paper}; we summarize the minor differences as they come up.

% except that (1) holes in \HazelnutLive each have a \emph{unique name};
% (2) for brevity of exposition, we removed numbers in favor of a simpler base type, $b$, with one value, $c$ (i.e. $b$ is the unit type); and
% (3) we include both unannotated lambdas, $\hlam{x}{\hexp}$, and half-annotated lambdas, $\halam{x}{\htau}{\hexp}$.  which we discuss
% (along with other systematic extensions) in
% Appendix~\ref{sec:extensions}.

\Figref{fig:bidirectional-typing} defines the type system in the \emph{bidirectional} style
%
with two mutually defined judgements \cite{Pierce:2000ve,bidi-tutorial,DBLP:conf/icfp/DunfieldK13,Chlipala:2005da}. The type synthesis
judgement~$\hsyn{\hGamma}{\hexp}{\htau}$ synthesizes a type~$\htau$
for external expression~$\hexp$ under typing context $\hGamma$, which tracks typing
assumptions of the form $x : \htau$ in the usual
manner \cite{pfpl,tapl}.
%
The type analysis judgement~$\hana{\hGamma}{\hexp}{\htau}$ checks
expression~$\hexp$ against a given type~$\htau$.
%
Algorithmically, analysis accepts a type as input, and synthesis gives
a type as output.
%
We start with synthesis for the programmer's top level external
expression.

% Algorithmically, the type is an output of type synthesis but an input of type analysis.

The primary benefit of specifying the \HazelnutLive external language
bidirectionally is that the programmer need not annotate each hole with a type.
%
An empty hole is
written simply $\hehole{u}$, where $u$ is the hole name, which we tacitly assume is unique
(holes in \Hazelnut were not named).
Rule \rulename{SEHole} specifies that an empty hole synthesizes hole type, written $\tehole$.
%
If an empty hole appears where an expression of some other type is
expected, e.g. under an explicit ascription (governed by Rule \rulename{SAsc})
or in the argument position of a function application (governed by
Rule \rulename{SAp}, discussed below), we apply the \emph{subsumption rule},
Rule \rulename{ASubsume}, which specifies that if an expression $e$ synthesizes
type $\htau$, then it may be checked against any \emph{consistent}
type, $\htau'$.

\input{fig-type-consistency}

Fig.~\ref{fig:tconsistent} specifies the type consistency relation, written $\tconsistent{\htau}{\htau'}$, which specifies that two types are consistent if they differ only up to type holes in corresponding positions.
%
The hole type is consistent with every type, and so, by the subsumption rule, expression holes may appear where an expression of any type is expected. The type consistency relation here coincides with the type consistency relation from gradual type theory by identifying the hole type with the unknown type~\cite{Siek06a}.
%
Type consistency is reflexive and symmetric, but it is \emph{not} transitive.
%
This stands in contrast to subtyping, which is anti-symmetric and transitive; subtyping may be integrated into a gradual type system following \citet{Siek:2007qy}.

Non-empty expression holes, written $\hhole{\hexp}{u}$, behave similarly to empty holes.
%
Rule \rulename{SNEHole} specifies that a non-empty expression hole also synthesizes hole type as long as the expression inside the hole, $\hexp$, synthesizes some (arbitrary) type.
%
Non-empty expression holes therefore internalize the ``red underline/outline'' that many editors display around type inconsistencies in a program.

For the familiar forms of the lambda calculus, the rules again follow prior work.
%
For simplicity, the core calculus includes only a single base type~$b$ with a single constant~$c$, governed by Rule \rulename{SConst} (i.e. $b$ is the unit type).
%
%\matt{Extraneous and uninteresting:}
By contrast, \citet{popl-paper} instead defined a number type with a single operation. That paper also defined sum types as an extension to the core calculus. We follow suit on both counts in \ifarxiv Appendix \ref{sec:extensions}\else the \appendixName\fi.%Appendix~\ref{sec:extensions}.
%

Rule \rulename{SVar} synthesizes the corresponding type from $\hGamma$.
For the sake of exposition, \HazelnutLive includes ``half-annotated'' lambdas, $\halam{x}{\htau}{\hexp}$, in addition to the unannotated lambdas, $\hlam{x}{\hexp}$, from \Hazelnut.
%
Half-annotated lambdas may appear in synthetic position according to Rule \rulename{SLam}, which is standard \cite{Chlipala:2005da}.
%
Unannotated lambdas may only appear where the expected type is known to be either an arrow type or the hole type, which is treated as if it were $\tarr{\tehole}{\tehole}$.\footnote{A system supporting ML-style type reconstruction \cite{damas1982principal} might also include a synthetic rule for unannotated lambdas, e.g. as outlined by \citet{DBLP:conf/icfp/DunfieldK13}, but we stick to this simpler ``Scala-style'' local type inference scheme in this paper \cite{Pierce:2000ve,Odersky:2001lb}.} 
%
To avoid the need for separate rules for these two cases, Rule \rulename{ALam} uses the matching relation $\arrmatch{\htau}{\tarr{\htau_1}{\htau_2}}$ defined in \Figref{fig:arrmatch}, which produces the matched arrow type $\tarr{\tehole}{\tehole}$ given the hole type, and operates as the identity on arrow types \cite{DBLP:conf/snapl/SiekVCB15,DBLP:conf/popl/GarciaC15}. The rule governing function application, Rule \rulename{SAp}, similarly treats an expression of hole type in function position as if it were of type $\tarr{\tehole}{\tehole}$ using the same matching relation.
%
% \Secref{sec:related} dicusses how \HazelnutLive might be enriched with
% with ML-style type reconstruction~\cite{damas1982principal}, perhaps via
% the approach outlined by~\citet{DBLP:conf/icfp/DunfieldK13}.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% To Cyrus from Matt:
%
% Why say the following here? --- It's discussing a different design that we didn't pursue here.  We should move such discussion to related work.
%
%Note that
%%


We do not formally need an explicit fixpoint operator because this calculus supports general recursion due to type holes, e.g. we can express the Y combinator as $(\halam{x}{\tehole}{x(x)}) (\halam{x}{\tehole}{x(x)})$. More generally, the untyped lambda calculus can be embedded as described by \citet{Siek06a}.
%As such, we omit an explicit fixpoint operator for concision.\todo{fixpoint?}{}

\vspace{-4px}
\subsection{Elaboration}
\label{sec:elaboration}
\vspace{-1px}

\input{fig-elab}
\input{fig-typing-dexp}

Each well-typed external expression~$e$ elaborates to a well-typed internal
expression~$d$, for evaluation.
%
\Figref{fig:elaboration} specifies elaboration, and \Figref{fig:hasType}
specifies type assignment for internal expressions.
%
% \Secref{sec:evaluation} discusses internal expression evaluation.

As with the type system for the external language (above), we specify
elaboration bidirectionally \cite{DBLP:conf/ppdp/FerreiraP14}.
%
The synthetic elaboration
judgement~$\elabSyn{\hGamma}{\hexp}{\htau}{\dexp}{\Delta}$
%
produces an elaboration~$d$ and a hole context~$\hDelta$ when synthesizing
type $\htau$ for $\hexp$.
%
%We say more about hole contexts, which are used in the type assignment judgement, $\hasType{\Delta}{\hGamma}{d}{\htau}$, below.
We describe hole contexts, which serve as ``inputs'' to the type assignment
judgement~$\hasType{\Delta}{\hGamma}{d}{\htau}$, further below.
%
The analytic elaboration
judgement~$\elabAna{\hGamma}{\hexp}{\htau}{\dexp}{\htau'}{\Delta}$,
produces an elaboration~$d$ of type~$\htau'$, and a hole context~$\hDelta$,
when checking~$\hexp$ against~$\htau$.
%
The following theorem establishes that elaborations are well-typed and in
the analytic case that the assigned type, $\htau'$, is consistent with
provided type, $\htau$.
%
\begin{thm}[Typed Elaboration]\label{thm:typed-elaboration} ~
  \begin{enumerate}[nolistsep]
    \item
      If $\elabSyn{\hGamma}{\hexp}{\htau}{\dexp}{\Delta}$
      then $\hasType{\Delta}{\hGamma}{\dexp}{\htau}$.
    \item
      If $\elabAna{\hGamma}{\hexp}{\htau}{\dexp}{\htau'}{\Delta}$ then
      $\tconsistent{\htau}{\htau'}$ and
      $\hasType{\Delta}{\hGamma}{\dexp}{\htau'}$.
  \end{enumerate}
\end{thm}
\noindent
%
%The reason analytic expansion produces an expansion of consistent
%type is because the subsumption rule, as previously discussed, allows
%us to check an external expression against any type consistent with
%the type the expression actually synthesizes, whereas every internal
%expression can be assigned at most one type, i.e. the following
%standard unicity property holds of the type assignment system.
%
The reason that $\htau'$ is only consistent with the provided type $\htau$ is because
%
the subsumption rule permits us to check an external expression against any
type consistent with the type that the expression \emph{actually}
synthesizes, whereas every internal expression can be assigned at most one
type, i.e. the following standard unicity property holds of the type
assignment system.
%
\begin{thm}[Type Assignment Unicity]
  If $\hasType{\Delta}{\hGamma}{\dexp}{\htau}$
  and $\hasType{\Delta}{\hGamma}{\dexp}{\htau'}$
  then $\htau=\htau'$.
\end{thm}
\noindent
Consequently, analytic elaboration reports the type actually assigned to
the elaboration it produces.
%
For example, we can derive that
$\elabAna{\hGamma}{c}{\tehole}{c}{b}{\emptyset}$.
% where $\emptyset$ is the empty hole context.

Before describing the rules in detail, let us state two other guiding
theorems.  The following theorem establishes that every well-typed external
expression can be elaborated.
 \begin{thm}[Elaborability] \label{thm:elaborability}~
  \begin{enumerate}[nolistsep]
    \item
      If $\hsyn{\hGamma}{\hexp}{\htau}$
      then $\elabSyn{\hGamma}{\hexp}{\htau}{\dexp}{\Delta}$
      for some $\dexp$ and $\Delta$.
    \item
      If $\hana{\hGamma}{\hexp}{\htau}$
      then $\elabAna{\hGamma}{\hexp}{\htau}{\dexp}{\htau'}{\Delta}$
      for some $\dexp$ and $\htau'$ and $\Delta$.
  \end{enumerate}
 \end{thm}

% \noindent
% The following theorem establishes that when an expansion exists, it is unique.
% \begin{thm}[Expansion Unicity] \label{thm:expansion-unicity}~
%   % \begin{enumerate}[nolistsep]
%   %   \item
%       If $\elabSyn{\hGamma}{\hexp}{\htau}{\dexp}{\Delta}$
%       and $\elabSyn{\hGamma}{\hexp}{\htau'}{\dexp'}{\Delta'}$
%       then $\htau=\htau'$ and $\dexp=\dexp'$ and $\Delta=\Delta'$.
%   %   \item
%   %     If $\elabAna{\hGamma}{\hexp}{\htau_1}{\dexp}{\htau_2}{\Delta}$
%   %     and $\elabAna{\hGamma}{\hexp}{\htau_1}{\dexp'}{\htau_2'}{\Delta'}$
%   %     then $\dexp=\dexp'$ and $\htau_2=\htau_2'$ and $\Delta=\Delta'$.
%   % \end{enumerate}
% \end{thm}
\noindent
The following theorem establishes that elaboration generalizes external
typing.
\begin{thm}[Elaboration Generality] \label{thm:elaboration-generality}~
  \begin{enumerate}[nolistsep]
    \item
      If $\elabSyn{\hGamma}{\hexp}{\htau}{\dexp}{\Delta}$
      then $\hsyn{\hGamma}{\hexp}{\htau}$.
    \item
      If $\elabAna{\hGamma}{\hexp}{\htau}{\dexp}{\htau'}{\Delta}$
      then $\hana{\hGamma}{\hexp}{\htau}$.
  \end{enumerate}
\end{thm}

We also establish that the elaboration produces unique results.
\begin{thm}[Elaboration Unicity] \label{thm:expansion-unicity}~
  \begin{enumerate}[nolistsep]
  \item If $\elabSyn{\hGamma}{\hexp}{\htau_1}{\dexp{}_1}{\Delta_1}$ and
    $\elabSyn{\hGamma}{\hexp}{\htau_2}{\dexp{}_2}{\Delta_2}$, then
    $\htau_1 = \htau_2$ and $\dexp{}_1 = \dexp{}_2$ and $\Delta_1 =
    \Delta_2$.
  \item If
    $\elabAna{\hGamma}{\hexp}{\htau}{\dexp{}_1}{\htau_1}{\Delta_1}$ and
    $\elabAna{\hGamma}{\hexp}{\htau}{\dexp{}_2}{\htau_2}{\Delta_2}$, then
    $\htau_1 = \htau_2$ and $\dexp{}_1 = \dexp{}_2$ and $\Delta_1 =
    \Delta_2$
  \end{enumerate}
\end{thm}

The rules governing elaboration of constants, variables and lambda
expressions---Rules \rulename{ESConst}, \rulename{ESVar}, \rulename{ESLam}
and \rulename{EALam}---mirror the corresponding type assignment rules---
Rules \rulename{TAConst}, \rulename{TAVar} and \rulename{TALam}---and in
turn, the corresponding bidirectional typing rules from
Fig.~\ref{fig:bidirectional-typing}.
%
% Consequently, the corresponding cases of
% Theorem~\ref{thm:typed-expansion}, Theorem~\ref{thm:expandability} and
% Theorem~\ref{thm:expansion-generality} are straightforward.
%
To support type assignment, all lambdas in the internal language are
half-annotated---Rule \rulename{EALam} inserts the annotation when
elaborating an unannotated external lambda based on the given type.
%
The rules governing hole elaboration, and the rules that perform \emph{cast
  insertion}---those governing function application and type
ascription---are more interesting. Let us consider each of these two groups
of rules in turn in Sec.~\ref{sec:hole-elaboration} and
Sec.~\ref{sec:cast-insertion}, respectively.

\subsubsection{Hole Elaboration}\label{sec:hole-elaboration}
Rules \rulename{ESEHole}, \rulename{ESNEHole}, \rulename{EAEHole} and
\rulename{EANEHole} govern the elaboration of empty and non-empty
expression holes to empty and non-empty \emph{hole closures},
$\dehole{u}{\sigma}{}$ and $\dhole{\dexp}{u}{\sigma}{}$.
%
The hole name~$u$ on a hole closure identifies the external hole to which
the hole closure corresponds.
%
While we assume each hole name to be unique in the external language, once
evaluation begins, there may be multiple hole closures with the same name
due to substitution.
%
For example, the result from Fig.~\ref{fig:grades-example} shows three
closures for the hole named 1.
%
There, we numbered each hole closure for a given hole sequentially,
\li{1:1}, \li{1:2} and \li{1:3}, but this is strictly for the sake of
presentation, so we omit hole closure numbers from the core calculus.

%
For each hole, $u$, in an external expression, the hole context generated
by elaboration, $\Delta$, contains a hypothesis of the
form~$\Dbinding{u}{\hGamma}{\htau}$, which records the hole's type, $\tau$,
and the typing context, $\Gamma$, from where it appears in the original
expression.\footnote{ We use a hole context, rather than recording the
  typing context and type directly on each hole closure, to ensure that all
  closures for a hole name have the same typing context and type.}
%
We borrow this hole context notation from contextual modal type theory
(CMTT) \cite{Nanevski2008}, identifying hole names with metavariables and
hole contexts with modal contexts (we say more about the connection with
CMTT below).
%
% Each hole expansion rule records the ``current'' typing context under which the hole is expanded.
%
In the synthetic hole elaboration rules~\rulename{ESEHole}
and~\rulename{ESNEHole}, the generated hole context assigns the hole
type~$\tehole$ to hole name~$u$, as in the external typing rules.
%
However, the first two premises of the elaboration subsumption
rule~\rulename{EASubsume} disallow the use of subsumption for holes in
analytic position.
%
Instead, we employ separate analytic rules~\rulename{EAEHole}
and~\rulename{EANEHole}, which each record the checked type~$\tau$ in the
hole context.
%
Consequently, we can use type assignment for the internal language --- the
type assignment rules \rulename{TAEHole} and \rulename{TANEHole} in
Fig.~\ref{fig:hasType} assign a hole closure for hole name~$u$ the
corresponding type from the hole context.

Each hole closure also has an associated environment~$\sigma$ which
consists of a finite substitution of the form $[d_1/x_1, ~\cdots, d_n/x_n]$
for $n \geq 0$.
%
The closure environment keeps a record of the substitutions that occur around the hole as evaluation occurs.
%
Initially, when no evaluation has yet occurred, the hole elaboration rules
generate the identity substitution for the typing context associated with
hole name~$u$ in hole context~$\Delta$, which we notate $\idof{\hGamma}$,
and define as follows.
%
\begin{defn}[Identity Substitution] $\idof{x_1 : \tau_1, ~\cdots, x_n : \tau_n} = [x_1/x_1, ~\cdots, x_n/x_n]$
\end{defn}
\noindent
The type assignment rules for hole closures,~\rulename{TAEHole} and \rulename{TANEHole}, each require that the hole closure environment~$\sigma$ be consistent with the corresponding typing context, written as $\hasType{\Delta}{\hGamma}{\sigma}{\hGamma'}$.
%
Formally, we define this relation in terms of type assignment as follows:
\begin{defn}[Substitution Typing]
$\hasType{\Delta}{\hGamma}{\sigma}{\hGamma'}$ iff $\domof{\sigma} = \domof{\hGamma'}$ and for each $x : \htau \in \hGamma'$ we have that $d/x \in \sigma$ and $\hasType{\Delta}{\hGamma}{d}{\tau}$.
\end{defn}
\noindent
It is easy to verify that the identity substitution satisfies this requirement, i.e. that $\hasType{\Delta}{\hGamma}{\idof{\hGamma}}{\hGamma}$.

Empty hole closures, $\dehole{u}{\sigma}{}$,  correspond to the metavariable closures (a.k.a. deferred substitutions) from CMTT, $\cmttclo{u}{\sigma}$.
%
\Secref{sec:evaluation} defines how these closure environments evolve during evaluation.
%
Non-empty hole closures~$\dhole{d}{u}{\sigma}{}$ have no direct correspondence with a notion from CMTT (see Sec.~\ref{sec:resumption}).

\subsubsection{Cast Insertion}\label{sec:cast-insertion}
%
% USE A TOPIC SENTENCE SO THAT THE READER IS GUIDED A LITTLE MORE, e.g.,
%
Holes in types require us to defer certain structural checks to run time.
%-----------------------------------------------------------------------------------------------
%
To see why this is necessary, consider the following
example: $\hap{(\halam{x}{\tehole}{\hap{x}{c}})}{c}$.
%
Viewed as an external expression, this example synthesizes type
$\tehole$, since the hole type annotation on variable~$x$ permits
applying~$x$ as a function of type~$\tarr{\tehole}{\tehole}$, and base
constant~$c$ may be checked against type~$\tehole$, by subsumption.
%
However, viewed as an internal expression, this example is not
well-typed---the type assignment system defined in
\Figref{fig:hasType} lacks subsumption.
%
Indeed, it would violate type safety if we could assign a type to this
example in the internal language, because beta reduction of this
example viewed as an internal expression would result in $c(c)$, which
is clearly not well-typed.
%
The difficulty arises because leaving the argument type unknown also leaves unknown how
the argument is being used (in this case, as a function).\footnote{In a system where type reconstruction is first used
to try to fill in type holes, we could express a similar example by
using $x$ at two or more different types, thereby causing type
reconstruction to fail.
%
% On the other hand, if it is acceptable to arbitrarily choose one of
%the possible types, and type reconstruction is complete, then type
%holes will never appear in the internal language and the cast
%insertion machinery described in this section can be omitted
%entirely, leaving only the hole closure machinery described
%previously.
}
By our interpretation of hole types as unknown types from gradual type
theory, we can address the problem by performing cast insertion.
%

The cast form in \HazelnutLive is $\dcasttwo{\dexp}{\htau_1}{\htau_2}$.
%
This form serves to ``box'' an expression of type $\htau_1$ for
treatment as an expression of a consistent type $\htau_2$
(Rule~\rulename{TACast} in \Figref{fig:hasType}).%
\footnote{
In the earliest work on gradual type theory, the cast form only gave
the target type~$\htau_2$ \cite{Siek06a}, but it simplifies the dynamic semantics substantially
to include the assigned type~$\htau_1$ in the syntax \cite{DBLP:conf/snapl/SiekVCB15}.
}

Elaboration inserts casts at function applications and ascriptions.
%
The latter is more straightforward: Rule~\rulename{ESAsc}
in \Figref{fig:expandSyn} inserts a cast from the assigned type to the
ascribed type.
%
Theorem~\ref{thm:typed-elaboration} inductively ensures that the two types
are consistent.
%
We include ascription for expository purposes---this form is derivable
by using application together with the half-annotated identity, $e
: \tau = \hap{(\halam{x}{\htau}{x})}{e}$; as such, application
elaboration, discussed below, is more general.

Rule~\rulename{ESAp} elaborates function applications.
%
To understand the rule, consider the elaboration of the example
discussed above, $\hap{(\halam{x}{\tehole}{\hap{x}{c}})}{c}$:
\[
        \hap{\dcasttwo{
        (\halam{x}{\tehole}{\underbrace{
                \hap{\dcasttwo{x}{\tehole}{\tarr{\tehole}{\tehole}}}
                {\dcasttwo{c}{b}{\tehole}}
                }_{\textrm{elaboration of function body}~x(c)}
        }
        )}{\tarr{\tehole}{\tehole}}{
           \tarr{\tehole}{\tehole}}
           }
           {\dcasttwo{c}{b}{\tehole}}
\]
Consider the (indicated) function body,
%
where elaboration inserts a cast on both the function expression~$x$ and
its argument~$c$.
%
Together, these casts for~$x$ and~$c$ permit assigning a type to the
function body according to the rules in \Figref{fig:hasType}, where we
could not do so under the same context without casts.
%
We separately consider the elaborations of~$x$ and of~$c$.

First, consider the function position of this application, here variable~$x$.
%
Without any cast, the type of variable~$x$ is the hole type~$\tehole$;
however, the inserted cast on~$x$ permits treating it as though it has
arrow type $\tarr{\tehole}{\tehole}$.
%
The first three premises of Rule~\rulename{ESAp} accomplish this
%
by first synthesizing a type for the function expression, here
$\tehole$, then
%
by determining the matched arrow type~$\tarr{\tehole}{\tehole}$, and
finally,
%
by performing analytic elaboration on the function expression with this
matched arrow type.
%
The resulting elaboration has some type~$\tau_1'$ consistent with the
matched arrow type.
%
In this case, because the subexpression~$x$ is a variable, analytic
elaboration goes through subsumption so that type~$\tau_1'$ is
simply~$\tehole$.
%
The conclusion of the rule inserts the corresponding cast.
%
We go through type synthesis, \emph{then} analytic elaboration, so that the
hole context records the matched arrow type for holes in function position,
rather than the type~$\tehole$ for all such holes, as would be the case in
a variant of this rule using synthetic elaboration for the function
expression.

Next, consider the application's argument, here constant~$c$.
%
The conclusion of Rule~\rulename{ESAp} inserts the cast on the argument's
elaboration, from the type it is assigned by the final premise of the
rule~(type~$b$), to the argument type of the matched arrow type of the
function expression~(type~$\tehole$).

The example's second, outermost application goes through the same
application elaboration rule.
%
In this case, the cast on the function is the identity cast for
$\tarr{\tehole}{\tehole}$.
%
For simplicity, we do not attempt to avoid the insertion of identity
casts in the core calculus; these will simply never fail during
evaluation.
%
However, it is safe in practice to eliminate such identity casts during
elaboration, and some formal accounts of gradual typing do so by defining
three application elaboration rules, including the original account of
\citet{Siek06a}.

\subsection{Dynamic Semantics}
\label{sec:evaluation}

To recap, the result of elaboration is a well-typed internal expression
with appropriately initialized hole closures and casts.  This section
specifies the dynamic semantics of \HazelnutLive as a ``small-step''
transition system over internal expressions equipped with a meaningful
notion of type safety even for incomplete programs, i.e. expressions typed
under a non-empty hole context, $\Delta$.  We establish that evaluation
does not stop immediately when it encounters a hole, nor when a cast fails,
by precisely characterizing when evaluation \emph{does} stop. In the case
of complete programs, we also recover the familiar statements of preservation
and progress for the simply typed lambda calculus.

% It is perhaps worth stating at the outset that a dynamic semantics equipped
% with these properties does not simply ``fall out'' from the observations
% made above that (1) empty hole closures correspond to metavariable closures
% from CMTT \cite{Nanevski2008} and (2) casts also arise in gradual type
% theory \cite{DBLP:conf/snapl/SiekVCB15}.
%
% We say more in Sec.~\ref{sec:relatedWork}.
%

%  specify the dynamic semantics of \HazelnutLive.
% %
% The dynamic semantics is capable of running incomplete programs, i.e. those with hole closures, without aborting at holes, or when a cast fails.
% %




\input{fig-ground-types}
\input{fig-dynamics-aux}



Figures~\ref{fig:isGround}-\ref{fig:step} define the dynamic semantics.
%
Most of the cast-related machinery closely follows the cast calculus from
the ``refined'' account of the gradually typed lambda calculus
by \citet{DBLP:conf/snapl/SiekVCB15}, which is known to be
theoretically well-behaved.
%
In particular, \Figref{fig:isGround} defines the judgement
$\isGround{\htau}$, which distinguishes the base type~$b$ and the
least specific arrow type~$\tarr{\tehole}{\tehole}$ as \emph{ground
types}; this judgement helps simplify the treatment of function casts, discussed below.

%
\Figref{fig:isFinal} defines the judgement $\isFinal{d}$, which
distinguishes the final, i.e. irreducible, forms of the transition system.
%
The two rules distinguish two classes of final forms: (possibly-)boxed values and
indeterminate forms.%
%
\footnote{
        Most accounts of the cast calculus distinguish ground types and values
        with separate grammars together with an
        implicit identification convention.
        %
        Our judgemental formulation is more faithful to the mechanization and
        cleaner for our purposes, because we are distinguishing several
        classes of final forms.
}
The judgement $\isBoxedValue{d}$ defines (possibly-)boxed values as either
ordinary values~(Rule~\rulename{BVVal}), or one of two cast forms: casts
between unequal function types and casts from a ground type to the hole
type. In each case, the cast must appear inductively on a boxed value.
These forms are irreducible because they represent values that have been
boxed but have never flowed into a corresponding ``unboxing'' cast,
discussed below.
%
%, which correspond to the values from the cast calculus and include
%the classic values from the lambda calculus, distingui%shed by
%$\isValue{d}$,
%
The judgement $\isIndet{d}$ defines \emph{indeterminate} forms, so named
because they are rooted at expression holes and failed casts, and so,
conceptually, their ultimate value awaits programmer action (see
Sec.~\ref{sec:resumption}). Note that no term is both complete, i.e. has no
holes, and indeterminate.
%
The first two rules specify that {empty} hole closures are always
indeterminate, and that {non}-empty hole closures are indeterminate when
they consist of a {final} inner expression.
%
Below, we describe failed casts and the remaining indeterminate forms simultaneously
with the corresponding transition rules.

Figures~\ref{fig:instruction-transitions}-\ref{fig:step} define the transition rules.
%
Top-level transitions are \emph{steps}, $\stepsToD{}{d}{d'}$, governed by Rule~\rulename{Step} in \Figref{fig:step}, which
%
(1) decomposes $d$ into an evaluation context, $\evalctx$, and a selected sub-term, $d_0$;
%
(2) takes an \emph{instruction transition}, $\reducesE{}{d_0}{d_0'}$, as specified in \Figref{fig:instruction-transitions};
%
and (3) places $d_0'$ back at the selected position, indicated in
the evaluation context by the \emph{mark}, $\evalhole$, to obtain $d'$.%
\footnote{
        We say ``mark'', rather than the more conventional ``hole'', to avoid confusion with the (orthogonal) holes of \HazelnutLive.
        %
        %the form $\evalhole$ in the grammar of
        %evaluation contexts is referred to as the \emph{hole}, but
        %this hole is a technical device entirely orthogonal to the
        %holes of this paper, so we use the term ``mark'' instead.
        }
%
%% \matt{Next paragraph can be dropped entirely for space}
%% %
This approach was originally developed in the reduction semantics of \citet{DBLP:journals/tcs/FelleisenH92} and is the predominant style of operational semantics in the literature on gradual typing.
Because we distinguish final forms judgementally, rather than syntactically, we use a judgemental formulation of this approach called a \emph{contextual dynamics} by \citet{pfpl}.
It would be straightforward to construct an equivalent structural operational semantics \cite{DBLP:journals/jlp/Plotkin04a} by using search rules instead of evaluation contexts (\citet{pfpl} relates the two approaches).

The rules maintain the property that final expressions truly cannot take a step.%
\begin{thm}[Finality] There does not exist $d$ such that both $\isFinal{d}$ and $\stepsToD{}{d}{d'}$ for some $d'$.
\end{thm}

%% \input{fig-dynamics-steps}

\subsubsection{Application and Substitution}
\input{fig-dynamics-contexts}
%
Rule \rulename{ITLam} in Fig.~\ref{fig:instruction-transitions} defines the
standard beta reduction transition.
%
The bracketed premises of the form $\maybePremise{\isFinal{\dexp}}$ in
Fig.~\ref{fig:instruction-transitions}-\ref{fig:step} may be \emph{included}
to specify an eager, left-to-right evaluation strategy, or \emph{excluded} to
leave the evaluation strategy and order unspecified.
%
In our metatheory, we exclude these premises, both for
the sake of generality, and to support the specification of the fill-and-resume operation~(see \Secref{sec:resumption}).



Substitution, written $[d/x]d'$, operates in the standard capture-avoiding manner~\cite{pfpl} (see \ifarxiv Appendix \ref{sec:substitution} \else the \appendixName~\fi for the full definition).
% Appendix~\ref{sec:additional-defns}).
%
The only cases of special interest arise when substitution reaches a hole closure:
\[
\begin{array}{rcl}
  [d/x]\dehole{u}{\sigma}{} & = & \dehole{u}{[d/x]\sigma}{} \\%
  \substitute{d}{x}{\dhole{d'}{u}{\sigma}{}} & = & \dhole{[d/x]d'}{u}{[d/x]\sigma}{}
\end{array}
\]
In both cases, we write~$[d/x]\sigma$ to perform substitution on each expression in the hole environment~$\sigma$, i.e. the environment ``records'' the substitution.
%
For example, $\stepsToD{}
    {\hap{(\halam{x}{b}{\halam{y}{b}{\dehole{u}{[x/x, y/y]}{}}})}{c}}
    {\halam{y}{b}{\dehole{u}{[c/x, y/y]}{}}}$.
%
Beta reduction can duplicate hole closures.
%
Consequently, the environments of different closures with the same hole name may differ,
e.g., when a reduction applies a function with a hole closure body multiple times as in Fig.~\ref{fig:grades-example}.
Hole closures may also appear within the environments of other hole
closures, giving rise to the closure paths described in
Sec.~\ref{sec:paths}.



The \rulename{ITLam} rule is not the only rule we need to handle function
application, because lambdas are not the only final form of arrow type.
%
Two other situations may also arise.

First, the expression in function position might be a cast between
arrow types, in which case we apply the arrow cast conversion rule,
Rule \rulename{ITApCast}, to rewrite the application form, obtaining an
equivalent application where the expression~$d_1$ under the function
cast is exposed.
%
We know from inverting the typing rules that~$d_1$ has type
$\tarr{\htau_1}{\htau_2}$, and that~$d_2$ has type~$\htau_1'$, where
$\tconsistent{\htau_1}{\htau_1'}$.
Consequently, we maintain type
safety by placing a cast on~$d_2$ from~$\htau_1'$ to~$\htau_1$.
%
The result of this application has type $\htau_2$, but the
original cast promised that the result would have consistent type
$\htau_2'$, so we also need a cast on the result from $\htau_2$ to
$\htau_2'$.

Second, the expression in function position may be indeterminate,
where arrow cast conversion is not applicable,
e.g. $\hap{(\dehole{u}{\sigma}{})}{c}$.
%
In this case, the application is indeterminate (Rule~\rulename{IAp}
in \Figref{fig:isFinal}), and the application reduces no
further.


\subsubsection{Casts}
Rule \rulename{ITCastId} strips identity casts. The remaining instruction
transition rules assign meaning to non-identity casts.
%
As discussed in Sec.~\ref{sec:cast-insertion}, the structure of a term
cast \emph{to} hole type is statically obscure,
%
so we must await a \emph{use} of the term at some other type, via a
cast \emph{away} from hole type, to detect the type error dynamically.
%
Rules \rulename{ITCastSucceed} and \rulename{ITCastFail} handle this situation when the
two types involved are ground types (Fig.~\ref{fig:isGround}).
%
If the two ground types are equal, then the cast succeeds and the cast
may be dropped.
%
If they are not equal, then the cast fails and the failed cast form,
$\dcastfail{\dexp}{\htau_1}{\htau_2}$, arises.
%
Rule \rulename{TAFailedCast} specifies that a failed cast is well-typed exactly
when $d$ has ground type $\tau_1$ and $\tau_2$ is a ground type
not equal to $\tau_1$.
%
Rule \rulename{IFailedCast} specifies that a failed cast operates as an
indeterminate form (once $d$ is final), i.e. evaluation does not stop. For simplicity, we do not include blame labels as found in some accounts of gradual typing \cite{DBLP:conf/esop/WadlerF09,DBLP:conf/snapl/SiekVCB15}, but it would be straightforward to do so by recording the blame labels from the two constituent casts on the two arrows of the failed cast.

% Rules \rulename{ITCastSucceed} and \rulename{ITCastFail} only operate at ground type.
%
The two remaining instruction transition rules, Rule~\rulename{ITGround}
and~\rulename{ITExpand}, insert intermediate casts from non-ground type to a
consistent ground type, and \emph{vice versa}.
%
These rules serve as technical devices, permitting us to restrict our
interest exclusively to casts involving ground types and type holes elsewhere.
%
Here, the only non-ground types are the arrow types, so the grounding
judgement~$\groundmatch{\tau_1}{\htau_2}$ (\Figref{fig:groundmatch}),
produces the ground arrow type~$\tarr{\tehole}{\tehole}$.
%
More generally, the following invariant governs this judgement.
\begin{lem}[Grounding]
  If $\groundmatch{\htau_1}{\htau_2}$
  then $\isGround{\htau_2}$
  and $\tconsistent{\htau_1}{\htau_2}$
  and $\htau_1\neq\htau_2$.
\end{lem}

In all other cases, casts evaluate either to boxed values or to
indeterminate forms according to the remaining rules
in \Figref{fig:isFinal}.
%
Of note, Rule \rulename{ICastHoleGround} handles casts from hole to
ground type that are not of
the form $\dcastthree{\dexp}{\htau_1}{\tehole}{\htau_2}$.
%

\subsubsection{Type Safety}
%
The purpose of establishing type safety is to ensure that the static and dynamic semantics of a
language cohere.
%
We follow the approach developed by \citet{wright94:_type_soundness},
now standard \cite{pfpl}, which distinguishes two type safety
properties, preservation and progress.
%
To permit the evaluation of incomplete programs, we establish these
properties for terms typed under arbitrary hole context $\Delta$.
%
We assume an empty typing context, $\hGamma$; to run open programs, the
system may treat free variables as empty holes with a corresponding
name.

The preservation theorem establishes that transitions preserve type
assignment, i.e. that the type of an expression accurately predicts
the type of the result of reducing that expression.

\begin{thm}[Preservation]
  If $\hasType{\Delta}{\emptyset}{\dexp}{\htau}$ and
  $\stepsToD{\Delta}{\dexp}{\dexp'}$ then
  $\hasType{\Delta}{\emptyset}{\dexp'}{\htau}$.
\end{thm}
\noindent
%
The proof relies on an analogous preservation lemma for instruction
transitions and a standard substitution lemma stated in \ifarxiv Appendix \ref{sec:substitution}\else the \appendixName\fi.
% Appendix~\ref{sec:additional-defns}.
%
Hole closures can disappear during evaluation, so we must have structural weakening 
of $\Delta$.

The progress theorem establishes that the dynamic semantics accounts
for every well-typed term, i.e. that we have not forgotten some
necessary rules or premises.
%
\begin{thm}[Progress]
  If $\hasType{\Delta}{\emptyset}{\dexp}{\htau}$ then either
  (a) there exists $\dexp'$ such that $\stepsToD{}{\dexp}{\dexp'}$ or
  (b) $\isBoxedValue{\dexp}$ or
  (c) $\isIndet{\dexp}$.
\end{thm}
\noindent
The key to establishing the progress theorem under a non-empty hole
context is to explicitly account for indeterminate forms,
i.e. those rooted at either a hole closure or a failed cast.
%
The proof relies on canonical forms lemmas stated in \ifarxiv Appendix~\ref{sec:canonical-forms}\else the \appendixName\fi.
% Appendix~\ref{sec:additional-defns}.

\subsubsection{Complete Programs}
%
Although this paper focuses on running \emph{incomplete} programs, it helps
to know that the necessary machinery does not interfere with running
\emph{complete} programs, i.e. those with no type or expression holes.
%
% Appendix~\ref{sec:additional-defns}
\ifarxiv Appendix~\ref{sec:complete-programs} \else The \appendixName{} \fi defines the predicates~$\isComplete{\htau}$,
$\isComplete{\hexp}$, $\isComplete{\dexp}$ and~$\isComplete{\hGamma}$.
%
Of note, failed casts cannot appear in complete internal expressions.
%
The following theorem establishes that elaboration preserves program
completeness.

\begin{thm}[Complete Elaboration]
% ~
  % \begin{enumerate}[nolistsep]
      If $\isComplete{\hGamma}$ and $\isComplete{\hexp}$
      and $\elabSyn{\hGamma}{\hexp}{\htau}{\dexp}{\Delta}$
      then $\isComplete{\htau}$ and $\isComplete{\dexp}$ and $\Delta = \emptyset$.
%     \item
%       If $\isComplete{\hGamma}$ and $\isComplete{\hexp}$
% and $\isComplete{\htau}$
%       and $\elabAna{\hGamma}{\hexp}{\htau}{\dexp}{\htau'}{\Delta}$
%       then $\isComplete{\dexp}$ and $\isComplete{\htau'}$ and $\Delta=\emptyset$
  % \end{enumerate}
\end{thm}

The following preservation theorem establishes that stepping preserves
program completeness.
\begin{thm}[Complete Preservation]
  If $\hasType{\hDelta}{\emptyset}{\dexp}{\htau}$
  and $\isComplete{\dexp}$
  and $\stepsToD{}{\dexp}{\dexp'}$
  then $\hasType{\hDelta}{\emptyset}{\dexp'}{\htau}$
  and $\isComplete{\dexp'}$.
\end{thm}

The following progress theorem establishes that evaluating a complete
program always results in classic values, not boxed values nor
indeterminate forms.
%
\begin{thm}[Complete Progress]
  If $\hasType{\hDelta}{\emptyset}{\dexp}{\htau}$ and $\isComplete{\dexp}$
  then either there exists a $\dexp'$ such that
  $\stepsToD{}{\dexp}{\dexp'}$, or $\isValue{\dexp}$.
\end{thm}

%% \begin{figure}[!ht]
%%   \begin{definition}
%%     $\hasType{\Delta}{\hGamma}{\sigma}{\hGamma'}$ iff for each $\dexp/x \in \sigma$, we have $x : \htau \in \hGamma'$ and $\hasType{\Delta}{\hGamma}{\dexp}{\htau}$.
%%   \end{definition}
%%   \caption{substitution type assignment}
%%   \label{fig:subassign}
%% \end{figure}


%% \begin{figure}[!ht]
%%   \caption{substitution type assignment}
%% \end{figure}

\vspace{-3px}
\subsection{Agda Mechanization}
\label{sec:agda-mechanization}
\vspace{-2px}

The archived artifact includes our Agda
mechanization  \cite{norell2009dependently,norell:thesis,Aydemir:2005fk}
of the semantics and metatheory of \HazelnutLive,
%including proofs of all of the
including all of the theorems stated above and necessary lemmas.
%
%We choose the
%(as did the mechanization of \Hazelnut by \citet{popl-paper}, though only a few definitions are common).
%
%Agda is a good choice because it is designed to explicitly communicate a proof's structure, as is our goal, rather than relying on proof automation.
%
%Agda itself was also an inspiration for this work because it supports holes, albeit in a more limited form than described here (cf. Sec.~\ref{sec:intro}).
%
%
Our approach is standard: we model judgements as
inductive datatypes, and rules as dependently typed constructors of these judgements.
%
We adopt Barendregt's convention for bound variables \cite{urban,barendregt84:_lambda_calculus} and hole names, and avoid certain other complications related to substitution by enforcing the requirement that all bound variables in a term are unique when convenient (this requirement can always be discharged by alpha-variation). We encode typing
contexts and hole contexts using metafunctions.
To support this encoding choice, we postulate function extensionality (which is independent of Agda's axioms) \cite{awodey2012inductive}. We encode finite substitutions as an inductive datatype with a base case representing the identity substitution and an inductive case that records a single substitution. Every finite substitution can be represented this way. This makes it easier for Agda to see why certain inductions that we perform are well-founded.  
The documentation provided with the mechanization has more details.

\vspace{-3px}
\subsection{Implementation and Continuity}\label{sec:implementation}
\vspace{-2px}

The \Hazel implementation described in Sec.~\ref{sec:examples}
includes an unoptimized interpreter, written in OCaml, that implements the semantics as described
in this section, with some simple extensions. As with many full-scale systems, there is not currently a formal
specification for the full \Hazel language, but \ifarxiv Appendix~\ref{sec:extensions} \else the \appendixName~\fi 
discusses how the standard approach for deriving a ``gradualized'' version of a
language construct provides most of the necessary scaffolding \cite{DBLP:conf/popl/CiminiS16}, and provides some examples (sum types and numbers).

% The supplemental material includes a browser-based implementation
% of \HazelnutLive.
% % The implementation supports the core calculus of this section but with the notional base type $b$ replaced by the $\tnum$ type from Appendix~\ref{sec:extensions}. The implementation also includes the sum types extension from Appendix~\ref{sec:extensions} and a few minor  conveniences, e.g. \li{let} binding.
% All of the live programming features from \Secref{sec:examples} are available in the implementation essentially as shown, but for this more austere language (with some minor conveniences, notably let binding). Appendix~\ref{sec:impl-screenshots} provides screenshots of the full user interface.

%  % which is a functional reactive program \cite{Elliott:1997jh,DBLP:conf/pldi/CzaplickiC13}
% %
% % Functional Reactive Animation (Hudak 1997) is the canonical FRP cite, not Elm, if you want one; we don't need one, I think. --Matt
% %
% %\cite{DBLP:conf/pldi/CzaplickiC13}

% The implementation is written with the Reason toolchain for OCaml \cite{reason-what,leroy03:_ocaml}
% together with the OCaml \lismall{React} library \cite{OcamlReact}
% and the \lismall{js_of_ocaml} compiler and its associated libraries \cite{vouillon2014bytecode}. This follows the implementation of \Hazel, which, although tracking toward an Elm-like semantics, is implemented in OCaml because the Elm compiler is not yet self-hosted. The implementation of the dynamic semantics consists of a simple evaluator that closely follows the rules specified in this section.

The editor component of the \Hazel implementation is derived
from the structure editor calculus of~\Hazelnut, but with support for more natural cursor-based movement and infix operator sequences (the details of which are beyond the scope of this paper). It exposes a language of structured
edit actions that automatically insert empty and non-empty holes as necessary
to guarantee that every edit state has some (possibly incomplete) type. This corresponds to the top-level Sensibility invariant established for the \Hazelnut calculus by \citet{popl-paper}, reproduced below:
\begin{prop}[Sensibility]
  \label{thrm:sensibility}
  If $\hsyn{\Gamma}{\removeSel{\zexp}}{\htau}$ and
    $\performSyn{\Gamma}{\zexp}{\htau}{\alpha}{\zexp'}{\tau'}$ then
    $\hsyn{\hGamma}{\removeSel{\zexp'}}{\htau'}$.
  % \item If $\hana{\hGamma}{\removeSel{\zexp}}{\htau}$ and
  %   $\performAna{\hGamma}{\zexp}{\htau}{\alpha}{\zexp'}$ then
  %   $\hana{\hGamma}{\removeSel{\zexp'}}{\htau}$.
\end{prop}
\noindent
Here, $\zexp$ is an editor state (an expression with a cursor), and $\removeSel{\zexp}$ drops the cursor, producing an expression ($e$ in this paper). So in words, ``if, ignoring the cursor, the editor state, $\removeSel{\zexp}$, initially has type $\htau$ and we perform an edit action $\alpha$ on it, then the resulting editor state, $\removeSel{\zexp'}$, will have type $\htau'$''.


By composing this Sensibility property with the \Property{Elaborability},
\Property{Typed Elaboration}, \Property{Progress} and
\Property{Preservation} properties from this section, we establish a
uniquely powerful Continuity invariant:
\begin{corol}[Continuity]
  \label{thrm:continuity}
  If $\hsyn{\emptyset}{\removeSel{\zexp}}{\htau}$ and
    $\performSyn{\emptyset}{\zexp}{\htau}{\alpha}{\zexp'}{\tau'}$ then
    $\elabSyn{\emptyset}{\removeSel{\zexp'}}{\htau'}{\dexp}{\Delta}$
      for some $\dexp$ and $\Delta$ such that
$\hasType{\Delta}{\emptyset}{\dexp}{\htau'}$
and either
  (a) $\stepsToD{}{\dexp}{\dexp'}$ for some $d'$ such that $\hasType{\Delta}{\emptyset}{\dexp'}{\htau'}$; or
  (b) $\isBoxedValue{\dexp}$ or
  (c) $\isIndet{\dexp}$.
  % \item If $\hana{\hGamma}{\removeSel{\zexp}}{\htau}$ and
  %   $\performAna{\hGamma}{\zexp}{\htau}{\alpha}{\zexp'}$ then
  %   $\hana{\hGamma}{\removeSel{\zexp'}}{\htau}$.
\end{corol}

This addresses the gap problem: \emph{every} editor state has a {static
meaning} (so editor services like the type inspector from Fig.~\ref{fig:qsort-type-inspector} are always available) and a non-trivial {dynamic meaning} (a result is always available, evaluation does not stop when a hole or cast failure is encountered, and editor services that rely on hole closures, like the live context inspector from Fig.~\ref{fig:grades-sidebar}, are always available).

In settings where the editor does not maintain this Sensibility invariant, but where programmers can manually insert holes, our approach still helps to reduce the severity of the gap problem, i.e. \emph{more} editor states are dynamically meaningful, even if not \emph{all} of them are.% We can formally state this end-to-end continuity corollary as follows:
%
% We make no further claims about the usability or practicality of the implementation (and indeed, there remain many important and decidedly unresolved questions along these lines, which we leave beyond the scope of this paper).
% We also reiterate that the essential ideas developed from type-theoretic first principles in this paper do not require that
% the editor component of the programming environment be implemented as a structure editor (see Sec.~\ref{sec:intro}).
 %,  to scale up these ideas to a ``real-world'' language and programming environment.

%, and provides to be of use to researchers studying the calculus as presented in this section.
% Consistent with this goal, it closely follows the theoretical account in this section, rather than including advanced language features.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% \matt{I'd drop everything else in this sub-section;
%% it leaves us open to attack from a hostile reviewer
%% who is cranky that the implementation is not ``complete'' yet; also, we'd save the space}

%%   \halam{x}{\htau}{\evalctx} ~\vert~

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand{\commutativitySec}{A Contextual Modal Interpretation of Fill-and-Resume}
\section{\commutativitySec}
\label{sec:resumption}


%The result of evaluation is a final internal expression with hole closures, each with an associated hole environment, $\sigma$. These hole environments can be reported directly to the programmer, e.g. via the sidebar shown in Fig.~X\todo{fig}, to help them as they think about how to fill in the corresponding hole in the external expression. Hole environments might also be useful indirectly, e.g. by informing an edit action synthesis and suggestion system. In any case,
When the programmer performs one or more edit actions to fill in an expression hole in the program, a new result must be computed, ideally quickly \cite{DBLP:conf/icse/Tanimoto13,DBLP:journals/vlc/Tanimoto90}. Na\"ively, the system would need to compute the result ``from scratch'' on each such edit. For small exploratory programming tasks, recomputation is acceptable, but in cases where a large amount of computation might occur, e.g. in data science tasks, a more efficient approach is to resume evaluation from where it left off after an edit that amounts to hole filling. This section develops a foundational account of this feature, which we call \emph{fill-and-resume}. This approach is complementary to, but distinct from, incremental computing (which is concerned with changes in input, not code insertions)~\cite{Hammer2014}.

%%%%%%%%% New par 
Formally,
%
the key idea is to interpret hole environments as \emph{delayed substitutions}. This is the same interpretation suggested for metavariable closures in contextual modal
type theory (CMTT) by \citet{Nanevski2008}.
%
%In practice, it may be useful to cache results from several previous
%expansions, e.g., by employing off-the-shelf programming language
%abstractions for incremental computation~\cite{Hammer14,Hammer15}.
%
%%%%%%%%% New par
\Figref{fig:substitution} defines the hole filling operation~$\instantiate{d}{u}{d'}$
based on the contextual substitution operation of~CMTT.
%
Unlike usual notions of capture-avoiding substitution,
hole filling imposes no condition on the binder when passing into the
body of a lambda expression---the expression that fills a hole can, of
course, refer to variables in scope where the hole appears.
%
When hole filling encounters an empty closure for the hole being
instantiated, $\instantiate{d}{u}{\dehole{u}{\sigma}{}}$, the result
is $[\instantiate{d}{u}{\sigma}]d$.
%
That is, we apply the delayed substitution to the fill expression~$d$
after first recursively filling any instances of hole~$u$ in~$\sigma$.
%
Hole filling for non-empty closures is analogous, where it discards
the previously-enveloped expression.
%
%
% \matt{Will any reader actually wonder this? Does this thought connect to any other statement elsewhere in the paper?}
%
This case shows why we cannot interpret a non-empty hole as an empty
hole of arrow type applied to the enveloped expression---the hole
filling operation would not operate as expected under this
interpretation.


\input{fig-substitution}

%%%%%%%%% New par
The following theorem characterizes the static behavior of hole filling.
\begin{thm}[Filling]
  If $\hasType{\hDelta, \Dbinding{u}{\hGamma'}{\htau'}}{\hGamma}{\dexp}{\tau}$
  and $\hasType{\hDelta}{\hGamma'}{\dexp'}{\htau'}$
  then $\hasType{\hDelta}{\hGamma}{\instantiate{\dexp'}{u}{\dexp}}{\tau}$.
\end{thm}

Dynamically, the correctness of fill-and-resume depends on
the following \emph{commutativity} property: if there is some sequence of
steps that go from $d_1$ to $d_2$, then one can fill a hole in these
terms at \emph{either} the beginning or at the end of that step
sequence.
%
We write $\multiStepsTo{\dexp_1}{\dexp_2}$ for the reflexive,
transitive closure of stepping (see \ifarxiv Appendix~\ref{sec:multi-step}\else the \appendixName\fi).
% Appendix~\ref{sec:additional-defns}).
%
\begin{thm}[Commutativity]
  If $\hasType{\hDelta, \Dbinding{u}{\hGamma'}{\htau'}}{\emptyset}{\dexp_1}{\tau}$
  and $\hasType{\hDelta}{\hGamma'}{\dexp'}{\htau'}$ and $\multiStepsTo{\dexp_1}{\dexp_2}$
  then $\multiStepsTo{\instantiate{\dexp'}{u}{\dexp_1}}
                     {\instantiate{\dexp'}{u}{\dexp_2}}$.
\end{thm}
%
The key idea is that we can resume evaluation by replaying the substitutions that were recorded in the closures and then taking the necessary ``catch up'' steps that evaluate the hole fillings that now appear.
%
The caveat is that resuming from $\instantiate{\dexp'}{u}{d_2}$ will not
reduce sub-expressions in the same order as a ``fresh'' eager left-to-right
reduction sequence starting from $\instantiate{\dexp'}{u}{d_1}$ so 
filling commutes with reduction only for 
languages where evaluation order ``does not matter'', e.g. pure functional languages like \HazelnutLive.\footnote{There are various standard ways to formalize this intuition, e.g. by stating a suitable confluence property. 
For the sake of space, we review confluence in \ifarxiv Appendix \ref{sec:confluence}\else the \appendixName\fi.} Languages with non-commutative effects do not enjoy this property.
% Appendix~\ref{sec:confluence}.)

%% Everyone knows what confluence means, or they should.  We don't need to cite Church :)
%%

We describe the proof, which is straightforward but involves a
number of lemmas and definitions, in \ifarxiv Appendix~\ref{sec:hole-filling}\else the \appendixName\fi.
%Appendix~\ref{sec:hole-filling}.
%
In particular, care is needed to handle the situation where a
now-filled non-empty hole had taken a step in the original evaluation trace.

% \matt{We could (should?) move the next paragraph to the appendix,
% before/after the proofs mentioned above;
% its not really adding much to the discussion above,
% but may be interesting to the very studious reader/prover; also, leaving it here also gives a lazy/cranky reviewer a nice weapon to hit us with}

We do not separately define hole filling in the external language (i.e. we
consider a change to an external expression to be a hole filling if the new
elaboration differs from the previous elaboration up to hole filling).  In
practice, it may be useful to cache more than one recent edit state to take
full advantage of hole filling.  As an example, consider two edits, the
first filling a hole~$u$ with the number~$2$, and the next applying
operator~$+$, resulting in $2 + \dehole{v}{\sigma}{}$.
%
This second edit is not a hole filling edit with respect to the
immediately preceding edit state, $2$, but it can be understood as filling
hole $u$ from two states back with $2 + \dehole{v}{\sigma}{}$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%5

Hole filling also allows us to give a contextual modal interpretation
to lab notebook cells  like those of
Jupyter/IPython \cite{PER-GRA:2007} (and read-eval-print loops as a restricted case
where edits to previous cells are impossible).
%
Each cell can be understood as a series of \li{let}
bindings ending implicitly in a hole, which is filled by the next cell.
The live environment in the subsequent cell is exactly the hole environment of this implicit trailing hole.
%
Hole filling when a subsequent cell changes avoids recomputing the
environment from preceding cells, without relying on mutable state. Commutativity provides a reproducibility guarantee
missing from Jupyter/IPython, where editing and executing previous cells can cause the state to differ substantially from the state that would result when attempting to run the notebook from the top.
% TODO citation


\begin{comment}

\begin{theorem}[Maximum Informativity]
If the elaboration produces $t1$, and there exists another possible type
choice $t2$, then $t1 \sim t2$ and $t1 JOIN t2 = t1$
\end{theorem}\footnote{idea is that special casing the holes in EANEHole gives you ``the
most descriptive hole types'' for some sense of what that means -- they'd
all just be hole other wise. from Matt:
\begin{quote}
It sounds like we need a something akin to an abstract domain (a lattice),
where hole has the least information, and a fully-defined type (without
holes) has the most information.  You can imagine that this lattice really
expands the existing definition we have of type consistency, which is
merely the predicate that says whether two types are comparable
(join-able) in this lattice.  lattice join is the operation that goes
through the structure of two (consistent) types, and chooses the structure
that is more defined (i.e., non-hole, if given the choice between hole and
non-hole).

The rule choosenonhole below is the expansion of this consistency rule that
we already have (hole consistent with everything)
\end{quote}}

\begin{verbatim}
t not hole
-------------------- :: choose-non-hole
hole JOIN t  = t
\end{verbatim}
\begin{verbatim}
------------ :: hole-consistent-with-everything
hole ~ t
\end{verbatim}

\end{comment}
