% !TEX root = hazelnut-dynamics.tex
\vspace{-5px}
\newcommand{\relatedWorkSection}{Related and Future Work}
\section{\protect\relatedWorkSection} % don't like the all-caps thing that the template does, so protecting it from that
\label{sec:relatedWork}
\vspace{-2px}

This paper builds directly on the static semantics developed by \citet{popl-paper}. That paper, as well as a subsequent ``vision paper'' introducing \Hazel \cite{HazelnutSNAPL}, suggested as future work  
a corresponding dynamic semantics for the purposes of live programming without gaps. \citet{Bayne:2011:ASD:1985793.1985864} have also extensively argued the value of assigning meaning even to incomplete and erroneous programs. 
This paper delivers conceptual and type-theoretic details necessary to advance these visions.

\parahead{Gradual Type Theory}

The semantics borrows machinery related to type holes from gradual type theory \cite{Siek06a,DBLP:conf/snapl/SiekVCB15}, as discussed
at length in Sec.~\ref{sec:calculus}. The main innovation relative to this
prior work is the treatment of cast failures like holes, rather than errors.
Many of the methods developed to make gradual type systems more expressive and practical are directly relevant to future directions for \Hazel and other implementations of the ideas herein \cite{takikawa_et_al:LIPIcs:2015:5215}. For example, there has been substantial work on the problem of implementing casts efficiently \cite{herman2010space,siek2010threesomes,garcia2013threesomes}. There has also been substantial work on integrating gradual typing with polymorphism \cite{DBLP:conf/esop/XieBO18,DBLP:journals/pacmpl/DevriesePP18,Igarashi:2017:PGT:3136534.3110284}, and with refinement types \cite{DBLP:conf/popl/LehmannT17}.

%% Although our expectation is that \Hazel will remain a pure functional language \emph{a la} \Elm~or Haskell,
%
Another interesting future direction would be to move beyond
pure functional programming and carefully integrate imperative features, e.g. ML-style references.
%
%% These require particular care, as recognized by \citet{Siek06a} and \citet{DBLP:conf/esop/SiekVCTG15}, but the techniques are known and we see no reason why the type safety properties  established in this paper would not be conserved, with suitable modifications to account for a store.
%
\citet{DBLP:conf/esop/SiekVCTG15} show how to incorporate such features into gradual type theory; we expect that this approach would also work for the semantics of Sec.~\ref{sec:calculus}, i.e. it would conserve the type safety properties established there, with suitable modifications to account for a store. However, the commutativity property we establish in Sec.~\ref{sec:resumption} will not hold for a language that supports non-commutative effects. We leave to future work the task of defining more restricted special cases of the fill-and-resume operation that respects a suitable commutativity property in effectful settings (perhaps by checkpointing or by using a type and effect system to granularly determine where re-evaluation is needed \cite{burckhardt2013s}).

%
Going beyond references to incorporate external effects, e.g. IO effects, raises some additional practical concerns, however---we do not want to continue past a hole or error and in so doing haphazardly trigger an unintended effect. In this setting, it is likely better to explicitly ask the programmer whether to continue evaluation past a hole or cast failure. The small step specification in this paper is suitable as the basis for a  step-based evaluator like this. \citet{ocaml-stepper} discuss some unresolved usability issues relevant to single steppers for functional languages. 

We did not give type holes unique names nor did we define a commutative type hole filling operation, but we conjecture that it is possible to do so by using non-empty expression holes to replace casts that go from the filled hole to an inconsistent type.


\parahead{Metavariables in Type Theory}

The other major pillar of related work is the work on contextual modal type theory (CMTT) by \citet{Nanevski2008}, which we also discussed at length throughout the paper. To reiterate, there is a close relationship between expression holes in this paper and metavariables in CMTT: both are associated with a type and a typing context. 
Empty hole closures 
relate to the concept of a {metavariable closure} (delayed substitution) in CMTT, which consists
of a metavariable paired with a substitution for all of the variables in the
typing context associated with that metavariable. 
Empty expression hole filling relates to contextual substitution. 

%% Although these connections with gradual typing and CMTT are encouraging, our contributions do not neatly fall out from this prior work.
%
These connections with gradual typing and CMTT are encouraging, but our contributions do not immediately fall out from this prior work.
%
The problem is first that \citet{Nanevski2008} defined only the logical reductions for CMTT, viewing it as a proof system for intuitionistic contextual modal logic via the propositions-as-types (Curry-Howard) principle. 
The paper therefore proved only a subject reduction property (which is closely related to type preservation) and sketched an interpretation of CMTT into the simply-typed lambda calculus with sums under permutation conversion, %, 
which has been studied by \citet{DBLP:journals/iandc/Groote02}. 
% Permutation conversions are necessary to encode the commuting reductions of CMTT, which in turn are necessary to prove a strong normalization property.
\citet{DBLP:conf/ppdp/PientkaD08} more directly defines a dynamic semantics for an extension of CMTT. In both cases, the issue is that these systems can evaluate only closed terms, while we need to consider terms with free metavariables. 

There has been much formal work on reduction of open terms. In particular, the typical approach is to define the \emph{weak head normal forms} \cite{barendregt84:_lambda_calculus,DBLP:journals/corr/abs-1009-2789,Abramsky:1990vv}, and a weak head normalization procedure. 
This is useful when using reduction to perform optimizations throughout a program, e.g. when using supercompilation-by-evaluation \cite{DBLP:conf/haskell/BolingbrokeJ10} or symbolic evaluation \cite{King:1976,SurveySymExec-CSUR18}, or when using evaluation in the service of equational reasoning as in dependently typed proof assistants. Notably, \citet{DBLP:journals/corr/abs-1009-2789} considered weak head normalization for CMTT, which forms the basis for equational reasoning in the Beluga proof assistant \cite{DBLP:conf/flops/Pientka10}. There are two points of note here. First, the addition of type holes allow us to express general recursion \cite{Siek06a}, so we cannot rely on normalization arguments and instead need a more conventional dynamic semantics with a progress theorem. Second, we do not want to evaluate under arbitrary binders but rather only around holes when they would otherwise have been evaluated \cite{DBLP:conf/birthday/BlancLM05}. As such, we do not need to consider terms with free variables, and can restrict our interest to only those with free metavariables. These considerations together lead us to the indeterminate forms and to the progress theorem that we established.

There are various other systems similar in many ways to CMTT in 
that they consider the problem of reasoning about metavariables. 
For example, McBride's OLEG is another system for reasoning contextually about metavariables
\cite{DBLP:phd/ethos/McBride00}, and it is the conceptual basis of certain hole refinement features in Idris \cite{brady2013idris}. \citet{DBLP:conf/csl/GeuversJ02} discuss similar ideas, again in the setting of hole refinement in proof assistants. However, these systems do not account for substitutions around metavariables. The systems underlying TypeLab \cite{Strecker:98a} and Alf \cite{magnusson1994implementation} do record substitutions around metavariables. These can be considered predecessors of CMTT, which is unique in that it has a clear Curry-Howard interpretation. The discussion above applies similarly to these systems.


We use the machinery 
borrowed from CMTT only extralinguistically.
%
A key feature of CMTT that we have not yet touched on is the
\emph{internalization} of metavariable binding and contextual
substitution via the contextual modal types, $[\hGamma]\htau$, which
are introduced by the operation $\mathsf{box}(\hGamma.d)$ and
eliminated by the operation $\mathsf{letbox}(d_1, u.d_2)$.
%
A program with expression holes can be interpretted as being bound under a number of these $\mathsf{letbox}$ constructs, i.e. CMTT serves as a ``{development calculus}'' \cite{DBLP:phd/ethos/McBride00}. Live programming corresponds to reduction under the metavariable binders interleaved with elimination steps. 
%
This suggests the possibility of \emph{computing} hole fillings by specifying a non-trivial expression of the appropriate contextual 
modal type in this development calculus.
%
This could, in turn, serve as the basis for a computational hole
refinement system that supports efficient live programming, extending the capabilities of purely static hole
refinement systems like those available in many languages,
e.g. the editor-integrated system of Idris
\cite{brady2013idris,Korkut:2018:ETE:3240719.3241791} and the hole refinement system of Beluga
\cite{DBLP:conf/flops/Pientka10,pientka2015inductive}.
%
Each applied hole filling can be interpretted as inducing a new dynamic
\emph{edit stage}.
%
This contextual modal interpretation of live hole refinement
nicely mirrors the modal interpretation of staging and partial evaluation
\cite{Davies:2001op}, with indeterminate forms corresponding to the residual programs that arise when performing partial evaluation. 
%
The difference is that staging and partial evaluation systems evaluate around an input that sits outside of a
function \cite{Jones:1993uq}, whereas holes are contextual, i.e. they are located inside the program. 

%
There is also more general work on explicit substitutions, which records all  substitutions, not just substitutions around metavariables, explicitly \cite{Abadi:1991fr,levy1999explicit,Abadi:1990ys}.  \citet{DBLP:journals/corr/abs-1009-2789} have developed a theory of explicit substitutions for CMTT, which, following other work on explicit substitutions and environmental abstract machines \cite{DBLP:journals/tcs/Curien91}, could be useful in implementing \HazelnutLive more efficiently by delaying both standard and contextual substitutions until needed during evaluation. We leave this and other questions of fast implementation (e.g. using thunks to encapsulate indeterminate sub-expressions) to future work. 

% We also cannot rely on, for example, weak head normalization because \HazelnutLive admits non-termination (due to casts).\todo{citation} 

% Furthermore, we need to integrate casts into the dynamic semantics. 
% Fortunately, the dynamic semantics for the cast calculus from the gradually typed lambda calculus provides most, but not all, of the necessary machinery. 
% The first problem is again with progress: in the cast calculus, the only irreducible terms of hole type are casts, which are accounted for by the progress theorem, but in $\HazelnutLive$, holes induce additional irreducible terms. 
% The second missing piece is that in prior work on casts, evaluation aborts when cast failure occurs. 
% Our goal, as discussed in Sec.~\ref{sec:failed-cast-example}\todo{where?}{}, is for cast failure to instead insert a membrane around the dynamic type error, 
% much like a non-empty hole serves as a membrane around a static type error, 
% allowing in both cases for evaluation to safely and meaningfully continue past the error when desired.



% \begin{itemize}
	%% \item Agda
	%% \item Idris
	%% \item GHC holes
	%% \item Visual Studio (and others) support for edit-and-resume
	% \item Scratch lets you just skip over statement holes
	% \item papers that show up in a search for ``typed holes'' -- \url{https://scholar.google.com/scholar?hl=en&as_sdt=0%2C39&q=%22typed+holes%22&btnG=}
% \end{itemize}


\parahead{Type Error Messages}

A key feature of our semantics is that it permits evaluation not only of terms with empty holes, but also terms with non-empty holes, i.e. reified static type inconsistencies. DuctileJ \cite{Bayne:2011:ASD:1985793.1985864} and GHC \cite{DBLP:conf/icfp/VytiniotisJM12} 
have also considered this problem, but have taken
an ``exceptional approach'' --- these systems can defer static type errors until run-time, but do not continue further once the term containing the error
 has been evaluated.

Understanding and debugging static type errors is notoriously difficult,
particularly for novices.
%
A variety of approaches have been
proposed to better localize
and explain type errors \cite{Seminal,ChenErwig2014,DBLP:journals/jfp/ChenE18,Pavlinovic2015,sherrloc}.
%
One of these approaches, by \citet{Seidel2016},  uses symbolic execution and program synthesis to generate a dynamic witness
that demonstrates a run-time failure that could be caused by the static type error.
%
\HazelnutLive{} has similar motivations in that it can run programs with type errors  and provide concrete feedback about the values that erroneous terms take during evaluation (Sec.~\ref{sec:static-errors}-\ref{sec:dynamic-type-errors}). However, no attempt is made to synthesize examples that do not already appear in the program. 
%
% Combining the strengths of these approaches may be fruitful in the future. 

\parahead{Coroutines} 
The fill-and-resume interaction is reminiscent of the interactions that occur when using coroutines \cite{DBLP:conf/ifip/KahnM77} and related mechanisms (e.g. algebraic effects) --  a coroutine might yield to the caller until a value is sent back in and then continue in the suspended environment. The difference is that 
the hole filling can make use of the context
around the hole. 

\parahead{Dynamic Error Propagation} 
\citet{DBLP:conf/sp/HritcuGKPM13} consider the problem of dynamic violations of information-flow control (IFC) policies. An exceptional approach here is problematic in practice, because it would lead critical systems to shutdown entirely. Instead, the authors develop several mechanisms for 
propagating errors through subsequent computations (in a manner that preserves non-interference properties). The most closely related is the NaV-lax approach, which turns errors into special ``not-a-value'' (NaV) terms that consume other terms that they interact with (like floating point NaN). Our approach differs in that terms are not consumed. Furthermore, we track hole closures and consider static and dynamic type errors, but not exception propagation.  

\parahead{Debuggers}

Our approach is reminiscent of the workflow that debuggers make available using breakpoints \cite{fitzgerald2008debugging,DBLP:journals/jfp/TolmachA95}, visualizers of program state \cite{Nelson2017,Guo13}, and a variety of logging and tracing capabilities.
%
Debuggers do not directly support incomplete programs, so the programmer first needs to insert suitable dummy exceptions as discussed in Sec.~\ref{sec:intro}.
%
Beyond that, there are two main distinctions. First, evaluation does not stop at each hole and so it is straightforward to explore the \emph{space} of values that a variable takes. Second, breakpoints, logs and tracing tools convey the values of a variable at a position in the evaluation trace. Hole closures, on the other hand, convey information from a syntactic position in the \emph{result} of evaluation. The result is, by nature, a simpler object than the trace. %  These approaches are fundamentally complementary in that standard debugging facilities are useful even when there are no holes in the program whereas our focus has been on incomplete programs. 

Some debuggers support ``edit-and-continue'', e.g. Visual Studio \cite{VSEditAndContinue} and Flutter \cite{flutter}, based on the dynamic software update (DSU) capabilities of the underlying run-time system \cite{DBLP:journals/toplas/StoyleHBSN07,DBLP:conf/vstte/HaydenMHFF12,DBLP:journals/toplas/HicksN05}. These features do not come with any guarantee that rerunning the program will produce the same result.


\parahead{Structure Editors}

Holes play a prominent role in structure editors, and indeed the prior work on \Hazelnut was primarily motivated by this application \cite{popl-paper}. 
Most work on structure editors has focused on the user interfaces that they
present. This is important work---presenting a fluid user interface involving
exclusively structural edit actions is a non-trivial problem that has not yet
been fully resolved, though recent studies have started to show productivity
gains for blocks-based structure editors like Scratch for novice programmers \cite{Resnick:2009:SP:1592761.1592779,DBLP:conf/chi/WeintropASFLSF18,DBLP:conf/acmidc/WeintropW15}, and for keyboard-driven structure
editors like \li{mbeddr} in professional programming settings~\cite{DBLP:conf/vl/Asenov014,DBLP:conf/sle/VolterSBK14,voelter_mbeddr:_2012}.
%
Some structure editors support live programming in various ways, e.g. Lamdu is a structure editor for a typed functional language that displays variable values inline based on recorded execution traces (see above) \cite{lamdu}. However, Lamdu takes the exceptional approach to holes. Scratch will execute a program with holes by simply skipping over incomplete commands, but this is a limited protocol because rerunning the program after filling the hole may produce a result unrelated to initial result. Though in some situations, skipping over problematic commands has been observed to work surprisingly well \cite{DBLP:conf/dac/Rinard12}, this paper focuses on a sound approach. 

\parahead{Scaling Challenges}

We make no empirical claims regarding the usability of the particular user interface presented in this paper. The \Hazel user interface as presented is a proof of concept
that demonstrates (1) a comprehensive solution to the gap problem, as described in Sec.~\ref{sec:implementation}; and 
(2) one possible user interface for presenting hole closures, including deeply nested hole closures, to the programmer. We leave detailed empirical evaluation to future work, and note that the purpose of defining a formal semantics is to provide a foundation for a variety of user interface experiments.

For larger programs, there are some limitations that will certainly require further UI refinement. 
Indeterminate results can get to be quite large, particularly when a hole or failed cast
appears in guard position as in Fig.~\ref{fig:cast-errors}. 
One approach is for the pretty printer can elide irrelevant branches. The semantics in Sec.~\ref{sec:calculus} would also allow for evaluation to pause when such
a form is produced, continuing only if requested. 

In larger programs, there can be many dozens of variables in scope, so search and sorting tools in the live context inspector would be useful. It would also be useful
to support the evaluation of arbitrary ``watched'' expressions in the selected 
closure. There are other ways to display the variable values, e.g. intercalated
into the code \cite{DBLP:journals/corr/abs-1806-07449,lamdu}.

Finally, we have not yet investigated nor attempted to optimize the memory and performance overhead of tracking hole closures. We note simply that it is often the case that 
programmers use small example inputs during initial development, providing larger inputs
only after the program is complete. There is no run-time overhead when there are no holes remaining.

% Finally, it is not always helpful to continue evaluation as far as possible.
% In particular, when there is a hole or cast failure in the argument position
% of a function application, it may often be more helpful to stop before 
% beta reduction, to avoid exposing the internals of the applied function to 
% the client. The semantics in Sec.~\ref{sec:calculus} leaves evaluation order
% undefined, so various heuristic approaches are possible (e.g. we might wish to avoid beta reduction  for functions from imported libraries).

% With sufficient UI advances, there is reason to believe that structure editing could be the foundation for a powerful ``next-generation'' live programming experience, and the \Hazel effort, with the contributions of our dynamic semantics, is actively exploring this direction. We emphasize, however,   
% that our proposed contributions will be relevant no matter how holes come to appear in a program, including when they are inserted manually (see Sec.~\ref{sec:implementation}). % We will say more about all of these systems later. 


% two main remaining questions (beyond scaling up the calculus) are how to run
% programs with type and expression holes.

% \begin{itemize}
% 	\item Hazelnut paper
% \end{itemize}

% \parahead{Gradual Typing}

% As already discussed in Track 1, type holes are closely related to the unknown
% types of gradual type theory \cite{Siek06a}. This has implications for our
% dynamic semantics as well---we need to be able to run programs where type holes
% have obscured a type inconsistency, \eg{}~\lstinline{let f(g : }\ \lstinline{) => g 3 in f 4}.
% This term is well-typed according to the static semantics of Track 1 because the
% argument \li{g} of \li{f} has an unknown type, and so it can be applied to
% \li{3}, but when \li{f} is applied to \li{4}, there is a problem because \li{4 3}
% is meaningless. There are two ways to address the problem. The first is to
% apply ML-style type inference to discover a more specific type schema for
% \li{g}, \ie{}~that it must actually be an arrow type, and then mark the argument
% \li{4} to \li{f} as a type inconsistency using a non-empty hole. We will
% investigate this in Track 1. The second approach is to adopt run-time cast
% insertions from research on gradual type theory. We will investigate this second
% approach in Track 2. 

% \begin{itemize}
% 	\item gradual typing (and dynamic typing)
%   \item siek and taha paper
%   \item snapl15 paper
%   \item gradualizer paper
%   \item maybe other things, e.g. several papers by ron garcia
% \end{itemize}

\parahead{Program Slicing}

Hole-like constructs also appear in work on program slicing
\cite{DBLP:conf/icfp/PereraACL12,DBLP:journals/pacmpl/RicciottiSPC17}, where empty expression holes arise as a technical device to determine which parts of a complete program do not impact a selected part of the result of evaluating that program. In other words, the focus is on explaining a result that is presumed to exist, whereas the work in this paper is focused on producing results where they would not have otherwise been available. Combining the strengths of these approaches is another fruitful avenue for future research.

\parahead{Program Synthesis}

Expression holes also often appear in the context of program synthesis, serving as
placeholders in \emph{templates}~\cite{srivastava2013template} or
\emph{sketches}~\cite{solar2009sketching} to be filled in by an expression
synthesis engine. We leave to future work the exciting possibility of combining these approaches. For example, one can imagine running an incomplete program as described in this paper and then adding tests or assertions about the value that a hole should take on under each of the different associated hole closures, via the live context inspector. These could serve as  constraints for use by a type-and-example-driven synthesis engine \cite{DBLP:conf/popl/FrankleOWZ16}. Relatedly, \emph{prorogued programming} proposes soliciting an external source, e.g. the programmer, for a suitable value when a hole is encountered \cite{DBLP:conf/oopsla/AfshariBS12}.

% \begin{itemize}
% 	\item work on debuggers that allow you to inspect environments
%   \item might be something relevant in the paper ``A Debugger for Standard ML'' 
%   \item "Visualizing the evaluation of functional programs for debugging" by Whitington and Ridge
%   \item "A lightweight interactive debugger for Haskell'' and ``Multiple-View Tracing for Haskell: a New Hat'' might be relevant
%   \item ocamli -- \url{https://github.com/johnwhitington/ocamli}
%   \item Better supporting debugging aids learning a novel programming language. -- Scaffidi at VLHCC 2017
%   \item quote from Wadler in ``Why no one uses functional languages'':
%     \begin{quote}
%     â€œ...there are few debuggers or
% profilers for strict [functional] languages, perhaps because constructing them is not considered
% research. This is a shame, since such tools are sorely needed, and there remains much of
% interest to learn about their construction and use.
%     \end{quote}
%    \item edit-and-resume in visual studio, others
% \end{itemize}

% Visual Studio edit-and-continue \url{https://docs.microsoft.com/en-us/visualstudio/debugger/edit-and-continue}
 

% \begin{itemize}
% 	% \item simply typed underdeterminism paper
% 	% \item DuctileJ stuff -- \url{https://homes.cs.washington.edu/~mernst/pubs/ductile-icse2011.pdf}
% 	% \item ``Achieving flexibility in direct-manipulation programming environments by relaxing the edit-time grammar'' -- \url{http://ieeexplore.ieee.org/document/1509511/}
% 	\item 
% \end{itemize}



